{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "YMmSY94FPmfm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "3j9lJHZyPmfo"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('news.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3Vs-l7-NPmfp",
        "outputId": "0c0b9731-839e-4f30-e8bb-85d1316f96b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                              title  \\\n",
              "0        8476                       You Can Smell Hillary’s Fear   \n",
              "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
              "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
              "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
              "4         875   The Battle of New York: Why This Primary Matters   \n",
              "\n",
              "                                                text label  \n",
              "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
              "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
              "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
              "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
              "4  It's primary day in New York and front-runners...  REAL  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ee4e7b4-db88-48c8-b81e-9e11fa76bd71\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8476</td>\n",
              "      <td>You Can Smell Hillary’s Fear</td>\n",
              "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10294</td>\n",
              "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
              "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3608</td>\n",
              "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
              "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10142</td>\n",
              "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
              "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>875</td>\n",
              "      <td>The Battle of New York: Why This Primary Matters</td>\n",
              "      <td>It's primary day in New York and front-runners...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ee4e7b4-db88-48c8-b81e-9e11fa76bd71')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9ee4e7b4-db88-48c8-b81e-9e11fa76bd71 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9ee4e7b4-db88-48c8-b81e-9e11fa76bd71');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bb426e85-3104-4909-b4b2-68864046d8fd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb426e85-3104-4909-b4b2-68864046d8fd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bb426e85-3104-4909-b4b2-68864046d8fd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6335,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3038,\n        \"min\": 2,\n        \"max\": 10557,\n        \"num_unique_values\": 6335,\n        \"samples\": [\n          9957,\n          7596,\n          8905\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6256,\n        \"samples\": [\n          \"Elizabeth Warren's speech attacking Donald Trump made a bigger argument about Republicans\",\n          \"Assange: Clinton And ISIS Are Funded By Same People, \\u201cTrump Not Permitted To Win\\u201d\",\n          \"Reporters Stunned to Learn Trump Fans Lining Up 12 Hours Before Rally Starts\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6060,\n        \"samples\": [\n          \"Republicans taking control of Congress this coming week will try to overcome their reputation as a divided party hobbled by infighting by working to reshape policy in ways that Americans will feel in corporate boardrooms, on factory floors and at the gas pump.\\n\\nIncoming committee chairmen are preparing fresh oversight of federal agencies while rank-and-file members will be encouraged to use a new budget plan and government spending bills to chip away at President Obama\\u2019s environmental regulations, health-care reform and outreach to Cuba and Iran.\\n\\nAfter years of sparring with the White House, Republicans are eager to demonstrate productivity and some level of bipartisan \\u00adcooperation with Obama and the Democrats. Public disgust with Washington gridlock remains high, and with the 2016 presidential campaign beginning in earnest, broader voter interest \\u2014 especially among independents and Democrats \\u2014 could put recent GOP gains at risk in less than two years.\\n\\n\\u201cOn the things where we agree, the goal will be to make a law, not just put something on [Obama\\u2019s] desk,\\u201d incoming Senate Majority Leader Mitch McConnell (R-Ky.) said in an interview, adding later: \\u201cI want to make it clear: Desire for a signature is not going to dictate everything that we do.\\u201d\\n\\nSecuring final passage of bills will require McConnell and House Speaker John A. Boehner (R-Ohio) to compromise with Democrats while holding together their own ranks, which have clashed repeatedly over issues such as spending and immigration. Many GOP leaders hope that their differences can be set aside in favor of legislative wins.\\n\\nThe House and Senate formally reconvene Tuesday. New members will be sworn in and top leaders and committee chairmen formally installed on a day steeped in tradition and ceremony.\\n\\nBoehner and McConnell will be backed by larger GOP majorities: 246 Republicans in the House \\u2014 the party\\u2019s largest majority since just after World War II \\u2014 and 54 GOP senators, an impressive gain but short of the 60 votes required to overcome most procedural hurdles that Democrats will have at their disposal.\\n\\nIn the Senate, the rebranding effort will begin with energy policy.\\n\\nMcConnell plans to start his tenure as Senate majority leader with a \\u201cfull-throated\\u201d debate on national energy policy, ranging from a new oil pipeline to additional oil exploration. He has also promised consideration of liberal alternatives.\\n\\nMcConnell wants to use the controversial proposal to authorize construction of the Keystone XL pipeline as the gen\\u00adesis for a free-wheeling Senate debate about the United States\\u2019 energy future, in which both sides will have the opportunity to offer and debate more expansive energy issues than the narrow pipeline proposal.\\n\\n\\u201cWe can treat this like a serious and significant energy debate,\\u201d McConnell said in an interview before Christmas in his Capitol office.\\n\\nObama has resisted GOP efforts to authorize the pipeline, but dozens of moderate congressional Democrats support the bill and a broader energy debate.\\n\\nOther Democrats are skeptical of McConnell\\u2019s plans.\\n\\n\\u201cThe $64,000 question as to whether the Congress can get anything done is which way the Republican leadership goes,\\u201d Sen. Charles E. Schumer (D-N.Y.) said in an interview Saturday. \\u201cIf they let the tea party pull them to the right into the path of negativity and obstruction, we\\u2019ll get nothing done.\\u201d\\n\\nSen. John Hoeven (R-N.D.), a lead author of the Keystone bill, said that Republicans plan to consider proposals allowing the export of liquefied natural gas; to give state governments greater power to oversee hydraulic fracturing; and to restrict the federal government\\u2019s role in the construction of cross-border gas pipelines.\\n\\n\\u201cI don\\u2019t think we have an energy bill that doesn\\u2019t have a Democratic co-sponsor on it,\\u201d he said. \\u201cBecause at the end of the day you\\u2019ve got to get at least 60 votes\\u201d to clear procedural hurdles.\\n\\nThe open process is part of McConnell\\u2019s effort to live up to his pledge to restore the Senate\\u2019s grand tradition of free and full debate, while also advancing conservative causes. A skilled practitioner in the use of the Senate\\u2019s arcane procedural rules to move or block legislation, McConnell has pledged to use those rules to score conservative wins. He has been coaching GOP senators that their most likely path to wins will come on the annual spending bills for the federal government \\u2014 which Republicans have routinely opposed on the grounds that they spend too much taxpayer money.\\n\\nOther party leaders echo those sentiments. \\u201cI think a majority [of Republicans] recognize that we have to govern responsibly,\\u201d said Sen. John McCain (R-Ariz.), who will become chairman of the Armed Services Committee. \\u201cWe have to show that we can be a productive party, and that, I think, will have a direct effect on whether we\\u2019re able to elect a Republican as president in 2016.\\u201d\\n\\nBut now, with control of the House and Senate, Republicans have more leeway to attach policy riders to spending bills that will restrict federal agencies in their oversight of environmental, labor and other regulations. These still may draw presidential vetoes, but McConnell believes that Republicans will have leverage to get some restrictions included, just as the mammoth spending measure approved last month included language sought by Wall Street firms making risky trades.\\n\\nIn the House, most of the early weeks will seem like a do-over of the past two years \\u2014 except that many of the bills passed will get swifter Senate consideration.\\n\\nUp first is a veterans employment bill that passed last year with bipartisan support, according to senior leadership aides. There is also a bill to loosen work requirements set by the Affordable Care Act and a similar bill to authorize the Keystone pipeline.\\n\\nThe second week of January will be devoted to a new spending plan for the Department of Homeland Security. The spending bill funds DHS only until the end of February, a move designed to give Republicans more time to craft a legislative response to Obama\\u2019s decision to change immigration policy through executive actions. But no specific proposals have emerged, the aides said.\\n\\nThen there are the investigations into alleged wrongdoing at agencies including the Internal Revenue Service, the Justice Department and the Environmental Protection Agency.\\n\\n\\u201cThere are issues that haven\\u2019t been resolved,\\u201d said Rep. Jason Chaffetz (R-Utah), the new chairman of the House Oversight and Government Reform Committee.\\n\\nHe is launching subcommittees to closely track Obama\\u2019s energy and environmental policies and created \\u201cadministrative rules,\\u201d a panel that will \\u201ctry to figure out what the administration is doing next with its rule-making authority. We\\u2019re going to jump on those as fast as we possibly can,\\u201d he said.\\n\\nBefore the work begins, Boehner is expected to face another leadership challenge. After he survived a close call two years ago, conservative blogs and radio shows are actively supporting another effort to unseat him.\\n\\nPresuming that the 434 currently seated House members show up to vote Tuesday and that all Democrats vote against him, at least 28 of the 246 Republicans also would need to vote against Boehner to deny him the gavel. (The 435th House seat is held by Rep. Michael G. Grimm (R-N.Y.), who plans to resign Monday after recently pleading guilty to tax evasion charges.)\\n\\nRep. Walter B. Jones (R-N.C.), who opposed Boehner two years ago, said in a recent radio interview that he\\u2019ll do it again, adding that at least 16 to 18 Republican members might vote against the speaker. Among them is Rep. Jim Bridenstine (R-Okla.), who said Friday that he will vote against the speaker because the spending bill passed last month didn\\u2019t fully strip DHS of its funding.\\n\\nRep. Tom Cole (R-Okla.), a Boehner ally, said in an interview that \\u201cI expect a few scattered \\u2018no\\u2019 votes. But because Boehner has been strengthened by the gains in the election, the speaker election should mostly be an uneventful coronation.\\u201d\\n\\nThe opening weeks of the new Congress are also expected to include the confirmation of Ashton Carter, Obama\\u2019s pick to lead the Pentagon, and Loretta Lynch to be the next attorney general. Concerns with Iran are also expected to be an early focus. The Obama administration persuaded Senate Democrats last year to hold off debating a bipartisan proposal authorizing stronger sanctions against the Iranian regime.\\n\\nBut Sen. Bob Corker (R-Tenn.), the incoming chairman of the Foreign Relations Committee, said, \\u201cMy guess is fairly early on in some form or fashion the Senate\\u2019s going to want to weigh in on Iran.\\u201d\\n\\nCorker also plans to launch \\u201ca rigorous hearing process\\u201d on Obama\\u2019s decision to restore diplomatic relations with Cuba. Republicans have threatened to block funding for a new embassy in Havana and confirmation of a new ambassador to Cuba. But Obama could veto spending bills that include such restrictions, sparking a showdown over whether the GOP is willing to shutter parts of the government over a new Cuba policy.\\n\\nIn 2016, Republicans will be defending at least 24 Senate seats and about a dozen first-term House members from swing districts around the country. Party leaders have a political imperative to govern and avoid short-term fights with Obama.\\n\\n\\u201cWe will see if there is an opportunity for a fourth quarter for President Obama that actually moves the country in the direction we\\u2019d like to go,\\u201d said Sen. Roger Wicker (R-Miss.), who also will be responsible for helping reelect GOP senators in 2016.\\n\\n\\u201cReagan did it a generation ago working with Democrats. Clinton did it almost two decades ago with welfare reform and deficit reduction,\\u201d he said. \\u201cSo it can be done \\u2014 if the president is disposed to move in that direction.\\u201d\",\n          \"Reps. Kevin McCarthy, R-California, Jason Chaffetz, R-Utah, and Daniel Webster, R-Florida, are the three candidates vying for the post, and the winner becomes the favorite to become second in line to succeed the President of the United States.\\n\\nBut Thursday's vote inside the House GOP conference is just the first step. The candidate who gets the Republican party's internal nod still has to be approved by the full House of Representatives on October 29. And that's where things can get tricky.\\n\\nIf the Republican nominee can't garner 218 votes on the House floor, then Boehner will remain the speaker. And the potential for multiple rounds of votes on the House floor could open up the election to other candidates beyond the three that are in the race now. It would also prolong the deeply divisive and public process for House Republicans, who are hoping to chart a new path forward and prove they can make the dysfunctional Capitol work.\\n\\nThe three candidates will make their pitch to GOP colleagues at a \\\"candidate forum\\\" on Thursday morning in a conference room in the basement of the Capitol. Each gets three minutes to make a speech before answering questions from members. At noon, the 247 members of the House Republican conference gather in the ornate Ways and Means Committee room to vote. Under the House GOP conference rules, the three candidates are not allowed to make their own speeches. Instead each can designate one supporter to make a three-minute address nominating them for the post. Then up to two additional supporters can speak for another minute each on the candidate's behalf. To win the GOP nomination, a candidate needs a simple majority of all House Republicans -- or 125 votes. (That number could change if any House Republicans are absent or opts not to vote in the election.) Boehner plans to vote for McCarthy before heading to New York to tape an appearance on \\\"The Tonight Show,\\\" according to a spokesman. The delegate from American Samoa, Amata Radewagen, who doesn't get a vote on the House floor, does get to cast a vote for speaker inside the conference meeting. RELATED: John Boehner to appear on 'The Tonight Show' Three members serve as \\\"tally clerks\\\" and collect the ballots and count how many votes each candidate receives. Once all the ballots are counted, a representative of the conference will announce the results, along with the vote totals. If no candidate gets a majority of the conference on the first vote, a second ballot circulates with the names of the top two vote-getters, and a winner is announced after those ballots are counted. The new speaker can't take the gavel from Boehner until the full House of Representatives votes. Unlike the private contest on Thursday, the floor vote is covered live by C-SPAN's television cameras inside the House chamber. Each member of Congress is called on in alphabetical order to stand and announce their choice for speaker. The winner must win the votes of a majority -- 218, if everyone in the House is present -- in order to win. The vast majority of House Democrats are expected for to vote for former Speaker and current Minority Leader Nancy Pelosi. House Republican conference rules require that GOP members support their party's nominee on the floor, but many conservatives have ignored that rule in recent elections. That's where any drama will occur. If the GOP nominee fails to get a majority, the contest on the House floor could go to multiple ballots. Boehner will remain the speaker until a majority of the House votes to elect a new candidate. The last time it took more than one ballot to elect a speaker was in 1923 when it took nine ballots over the course of three days. And you don't need to be in the House to get the job. The Constitution does not require that the speaker be someone currently serving in Congress, but all who have been elected to the post have been House members. Former Secretary of State Colin Powell, Sen. Rand Paul and Sen. Jeff Sessions received votes in the January 2015 election . And two years earlier, David Walker, the former head of the General Accounting Office, received one vote\",\n          \"Over the last six years, the Obama administration has been trying to address global warming\\u00a0with a flurry of rules aimed at reducing US carbon-dioxide emissions. First there were stricter fuel-economy standards for cars and trucks. More recently, the EPA\\u00a0proposed sweeping carbon regulations for coal-fired power plants (known as the \\\"Clean Power Plan\\\").\\n\\nThe overarching goal was to cut US greenhouse-gas emissions 17 percent below 2005 levels by 2020. That, the administration believed, would help advance global climate talks.\\n\\nBut all of Obama's moves so far\\u00a0have been insufficient to get to that 17 percent cut by 2020. As recent analyses from the Rhodium Group and the Clean Air Task Force\\u00a0have argued, the US also needs to reduce methane emissions dramatically to get there:\\n\\nCarbon-dioxide is the biggest greenhouse gas responsible for global warming. But it's not the only one. There's also\\u00a0methane.\\u00a0The US burns a lot of methane \\u2014 known as \\\"natural gas\\\" \\u2014 for energy. But when methane leaks out of oil and gas wells or pipelines and into the atmosphere, it acts as a potent greenhouse gas. (The White House says it's 25 times as effective at trapping heat as carbon dioxide. Other scientists say 34 times.)\\n\\nIn 2012, the EPA estimated that methane accounted for roughly\\u00a08.7 percent of US greenhouse-gas emissions (though this may be an\\u00a0underestimate). But experts have warned that methane leaks could be poised to grow in the coming years.\\n\\nThanks to the\\u00a0fracking boom, US energy companies have been extracting more and more natural gas from shale formations. On one level, that's good news for climate change: utilities are now burning more natural gas for electricity instead of coal, which means lower carbon-dioxide emissions from power plants.\\n\\nThe problem is that all this new drilling increases the risk of methane leaking into the air \\u2014 and those leaks\\u00a0are undermining the climate benefits of the gas boom.\\n\\nIn theory, it should be doable to plug these methane emissions,\\u00a0which can come from leaky pipelines or faulty drilling operations. Many companies already\\u00a0use infrared cameras to detect leaks and plug them. And they have financial incentives to do so \\u2014 after all, these companies would rather capture that methane and sell it for money than just have it float off into the air.\\n\\nMany oil and gas companies are already taking steps to detect and plug leaks\\n\\nStill, the White House wants to make sure these leaks really get plugged. So, on Wednesday, it\\u00a0announced a goal of cutting methane emissions from oil and gas operations 45 percent below 2012 levels by 2025.\\n\\nThis would be done through a combination of guidelines for voluntary actions by the industry and a hodgepodge of new regulations\\u00a0crafted by the EPA and other agencies. Some rules would focus on methane leaks from new oil and gas wells. Others would focus on pipelines used to transport the natural gas. The Interior Department is updating standards for drilling on public lands.\\n\\nThe White House noted that the oil and gas industry has already managed to cut methane emissions 16 percent since 1990 through voluntary measures. \\\"Nevertheless,\\\" it added, \\\"emissions from the oil and gas sector are projected to rise more than 25 percent by 2025 without additional steps to lower them.\\\"\\n\\nSome environmental groups said the White House's plan didn't go far enough. For example, the EPA is currently only working on rules to reduce emissions at new oil and gas wells \\u2014 and only much later will they work on rules for\\u00a0existing wells, which are by far the biggest source of emissions.\\n\\n\\\"While setting methane standards for the first time is an important step, failing to immediately regulate existing oil and gas equipment nationwide misses 90% of the methane pollution from the industry,\\\" Conrad Schneider of the Clean Air Task Force said in a statement.\\n\\nJayni Hein, policy director at the Institute for Policy Integrity at NYU School of Law, agreed: \\\"EPA's steps announced today would trim the sector's methane releases by about a third. We can and should go farther by regulating existing oil and natural gas sources.\\\"\\n\\nBy contrast, many oil and gas companies don't want new regulations at all \\u2014 they argue that the industry is already curbing methane leaks as is.\\u00a0\\\"Emissions will continue to fall as operators innovate and find new ways to capture and deliver more methane to consumers,\\\" said Jack Gerard, head of the American Petroleum Institute, in a statement. \\\"Existing EPA and state regulations are working. Another layer of burdensome requirements could actually slow down industry progress to reduce methane emissions.\\\"\\n\\nMeanwhile, it's worth noting that there are other sources of methane besides oil and gas. In 2012,\\u00a0according to the EPA, roughly 30 percent of methane in the United States came from natural-gas and petroleum operations (though, again, that may be an undercount).\\n\\nObama is relying on voluntary measures for methane in agriculture\\n\\n-- By contrast,\\u00a036 percent of US.methane emissions came from agriculture. The beef and dairy industry is a major contributor here: when cows belch, they produce methane (known as \\\"enteric fermentation\\\"). Other sources include decomposing cow manure, as well as methane from rice cultivation.\\n\\n-- Another\\u00a018 percent came from landfills. When food and other trash decays in a landfill, the organisms that feed on that trash emit methane into the atmosphere.\\n\\nThe Obama administration\\u00a0has been working on steps to cut methane in these areas, too. Back in March, the EPA announced it would come up with standards to reduce methane from all future landfills. It will then solicit public comments on whether to regulate landfills that have already been built.\\n\\nAs for cow burps, however, the administration is relying on purely voluntary measures for now. In June 2014, the EPA unveiled a \\\"partnership\\\" with the dairy industry to speed up the adoption of methane digesters that turn cow dung into energy. The hope is to reduce methane emissions from the dairy sector 25 percent by 2020.\\n\\nFurther reading: Obama has promised to cut US emissions 17% by 2020. Is that still possible?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"REAL\",\n          \"FAKE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDUBl2HhPmfs",
        "outputId": "6a3760ce-f46b-4e5e-e300-2490e2d077d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6335 entries, 0 to 6334\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Unnamed: 0  6335 non-null   int64 \n",
            " 1   title       6335 non-null   object\n",
            " 2   text        6335 non-null   object\n",
            " 3   label       6335 non-null   object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 198.1+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rNycMOtPmfu",
        "outputId": "12af6ad4-e8ad-4fc0-e4bd-5d0d4265c74b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6335, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "ToMrH2DePmfu",
        "outputId": "eadb11af-bfe6-43c2-f8f9-f318c0363c24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0    0\n",
              "title         0\n",
              "text          0\n",
              "label         0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>title</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POL6NqB8Pmfv",
        "outputId": "26c22063-970f-479a-b799-f0f9de8a7002"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['FAKE', 'REAL'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "df['label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "PQMgaxTkPmfw",
        "outputId": "48f5d967-0b47-4ed5-975b-cb2018aaa0d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "REAL    3171\n",
              "FAKE    3164\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>REAL</th>\n",
              "      <td>3171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FAKE</th>\n",
              "      <td>3164</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuko94EDPmfw"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: apply label encoding on sentiment colunm\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['label'] = le.fit_transform(df['label'])\n",
        "df['label'].value_counts()\n",
        "\n",
        "\n",
        "\n",
        "with open('label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(le, f)\n",
        "\n"
      ],
      "metadata": {
        "id": "wD_K153deHrj"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ILlsGEotPmfy"
      },
      "outputs": [],
      "source": [
        "df['title'] = df['title'].str.lower()\n",
        "df['text'] = df['text'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df[['title','text']]\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "rlDtoLXlVmOB"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Removing special characters, URLs, HTML tags, and extra spaces\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z0-9]+', ' ', text)\n",
        "    text = re.sub(r'(http|https|ftp)://[a-zA-Z0-9./]+', '', text)\n",
        "    text = BeautifulSoup(text, 'lxml').get_text()\n",
        "    text = \" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing to both 'text' and 'title' columns\n",
        "for col in ['text', 'title']:\n",
        "    X_train[col] = X_train[col].apply(preprocess_text)\n",
        "    X_test[col] = X_test[col].apply(preprocess_text)\n",
        "\n",
        "# Remove stopwords from both 'text' and 'title' columns\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def remove_stopwords(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in stop_words])\n",
        "\n",
        "for col in ['text', 'title']:\n",
        "    X_train[col] = X_train[col].apply(remove_stopwords)\n",
        "    X_test[col] = X_test[col].apply(remove_stopwords)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2Frb9tsZdF5",
        "outputId": "32f54e63-40a9-44db-e3ed-459df4d54b09"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (5068, 2)\n",
            "y_train shape: (5068,)\n",
            "X_test shape: (1267, 2)\n",
            "y_test shape: (1267,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: do tokenization and apply lemmitization\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download required NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "# Tokenization and Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def tokenize_and_lemmatize(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return \" \".join(lemmas)\n",
        "\n",
        "for col in ['text', 'title']:\n",
        "    X_train[col] = X_train[col].apply(tokenize_and_lemmatize)\n",
        "    X_test[col] = X_test[col].apply(tokenize_and_lemmatize)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnrcg35a8na2",
        "outputId": "eddea3f6-b99c-46a8-bfd4-dc210025fc50"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (5068, 2)\n",
            "y_train shape: (5068,)\n",
            "X_test shape: (1267, 2)\n",
            "y_test shape: (1267,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: apply tfidf according to i=our file\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Combine 'title' and 'text' columns for TF-IDF\n",
        "X_train['combined'] = X_train['title'] + ' ' + X_train['text']\n",
        "X_test['combined'] = X_test['title'] + ' ' + X_test['text']\n",
        "\n",
        "# Create a TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000) # Adjust max_features as needed\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['combined'])\n",
        "\n",
        "# Transform the testing data\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test['combined'])\n",
        "\n",
        "print(f\"X_train_tfidf shape: {X_train_tfidf.shape}\")\n",
        "print(f\"X_test_tfidf shape: {X_test_tfidf.shape}\")\n",
        "\n",
        "\n",
        "# Save vectorizer\n",
        "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tfidf_vectorizer, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGo-NNTI9qmZ",
        "outputId": "b797b113-4fea-41a6-beb0-6fb1266f2554"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_tfidf shape: (5068, 5000)\n",
            "X_test_tfidf shape: (1267, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: install keras\n",
        "\n",
        "!pip install keras\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r9TnLqr-3wK",
        "outputId": "2643f515-562d-4878-ae29-5e1212a9d8f3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.naive_bayes import MultinomialNB\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# models = {\n",
        "#     'Naive Bayes': MultinomialNB(),\n",
        "#     'Random Forest': RandomForestClassifier(),\n",
        "# }\n",
        "\n",
        "# for model_name, model in models.items():\n",
        "#     model.fit(X_train_tfidf, y_train)\n",
        "#     y_train_pred = model.predict(X_train_tfidf)\n",
        "#     y_test_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "#     print(model_name)\n",
        "#     print('Training Set Performance')\n",
        "#     print('accuracy_score {:.4f}'.format(accuracy_score(y_train, y_train_pred)))\n",
        "#     print('f1_score {:.4f}'.format(f1_score(y_train, y_train_pred, average='weighted')))\n",
        "#     print('precision_score {:.4f}'.format(precision_score(y_train, y_train_pred, average='weighted')))\n",
        "#     print('recall_score {:.4f}'.format(recall_score(y_train, y_train_pred, average='weighted')))\n",
        "#     print('roc_auc_score {:.4f}'.format(roc_auc_score(y_train, y_train_pred, average='weighted')))\n",
        "#     print('--------------------------')\n",
        "#     print('Test Set Performance')\n",
        "#     print('accuracy_score {:.4f}'.format(accuracy_score(y_test, y_test_pred)))\n",
        "#     print('f1_score {:.4f}'.format(f1_score(y_test, y_test_pred, average='weighted')))\n",
        "#     print('precision_score {:.4f}'.format(precision_score(y_test, y_test_pred, average='weighted')))\n",
        "#     print('recall_score {:.4f}'.format(recall_score(y_test, y_test_pred, average='weighted')))\n",
        "#     print('roc_auc_score {:.4f}'.format(roc_auc_score(y_test, y_test_pred, average='weighted')))\n",
        "#     print('=' * 35)\n",
        "#     print('\\n')\n",
        "\n",
        "#     filename = f'{model_name.lower().replace(\" \", \"_\")}_model.pkl'\n",
        "#     with open(filename, 'wb') as f:\n",
        "#         pickle.dump(model, f)\n",
        "\n",
        "# # what is LSTM\n",
        "# # LSTM Model\n",
        "# # Tokenize the text data\n",
        "# tokenizer = Tokenizer(num_words=5000) # Adjust num_words as needed\n",
        "# tokenizer.fit_on_texts(X_train['combined'])\n",
        "\n",
        "# X_train_seq = tokenizer.texts_to_sequences(X_train['combined'])\n",
        "# X_test_seq = tokenizer.texts_to_sequences(X_test['combined'])\n",
        "\n",
        "# max_length = 200  # Adjust max_length as needed\n",
        "# X_train_pad = pad_sequences(X_train_seq, maxlen=max_length)\n",
        "# X_test_pad = pad_sequences(X_test_seq, maxlen=max_length)\n",
        "\n",
        "# # Define the LSTM model\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(5000, 128, input_length=max_length))\n",
        "# model.add(LSTM(64))\n",
        "# model.add(Dense(1, activation='sigmoid')) # Assuming binary classification\n",
        "\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# model.fit(X_train_pad, y_train, epochs=5, batch_size=64) # adjust epochs and batch_size\n",
        "\n",
        "# y_train_pred_lstm = (model.predict(X_train_pad) > 0.5).astype(int)\n",
        "# y_test_pred_lstm = (model.predict(X_test_pad) > 0.5).astype(int)\n",
        "\n",
        "\n",
        "# # Evaluate LSTM model\n",
        "# print('LSTM')\n",
        "# # ... (similar evaluation code for LSTM using y_train_pred_lstm and y_test_pred_lstm)\n",
        "# # save the tokenizer\n",
        "# with open('tokenizer.pkl', 'wb') as handle:\n",
        "#     pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# model.save('lstm_model.h5')\n"
      ],
      "metadata": {
        "id": "hMLQ6Wcp-eT1"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Initialize variables to track the best model and its performance\n",
        "best_model = None\n",
        "best_f1_score = 0\n",
        "best_model_name = \"\"\n",
        "\n",
        "# Traditional models (Naive Bayes, Random Forest)\n",
        "models = {\n",
        "    'Naive Bayes': MultinomialNB(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "}\n",
        "\n",
        "# Loop through the models for training and evaluation\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "    y_train_pred = model.predict(X_train_tfidf)\n",
        "    y_test_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "    print(model_name)\n",
        "    print('Training Set Performance')\n",
        "    print('accuracy_score {:.4f}'.format(accuracy_score(y_train, y_train_pred)))\n",
        "    print('f1_score {:.4f}'.format(f1_score(y_train, y_train_pred, average='weighted')))\n",
        "    print('precision_score {:.4f}'.format(precision_score(y_train, y_train_pred, average='weighted')))\n",
        "    print('recall_score {:.4f}'.format(recall_score(y_train, y_train_pred, average='weighted')))\n",
        "    print('roc_auc_score {:.4f}'.format(roc_auc_score(y_train, y_train_pred, average='weighted')))\n",
        "    print('--------------------------')\n",
        "    print('Test Set Performance')\n",
        "    print('accuracy_score {:.4f}'.format(accuracy_score(y_test, y_test_pred)))\n",
        "    print('f1_score {:.4f}'.format(f1_score(y_test, y_test_pred, average='weighted')))\n",
        "    print('precision_score {:.4f}'.format(precision_score(y_test, y_test_pred, average='weighted')))\n",
        "    print('recall_score {:.4f}'.format(recall_score(y_test, y_test_pred, average='weighted')))\n",
        "    print('roc_auc_score {:.4f}'.format(roc_auc_score(y_test, y_test_pred, average='weighted')))\n",
        "    print('=' * 35)\n",
        "    print('\\n')\n",
        "\n",
        "    # Check if this model has the best F1 score so far\n",
        "    model_f1_score = f1_score(y_test, y_test_pred, average='weighted')\n",
        "    if model_f1_score > best_f1_score:\n",
        "        best_f1_score = model_f1_score\n",
        "        best_model = model\n",
        "        best_model_name = model_name\n",
        "\n",
        "    # Save each model\n",
        "    filename = f'{model_name.lower().replace(\" \", \"_\")}_model.pkl'\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "# LSTM Model\n",
        "# Tokenize the text data for LSTM model\n",
        "tokenizer = Tokenizer(num_words=5000) # Adjust num_words as needed\n",
        "tokenizer.fit_on_texts(X_train['combined'])\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train['combined'])\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test['combined'])\n",
        "\n",
        "max_length = 200  # Adjust max_length as needed\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length)\n",
        "\n",
        "# Define the LSTM model without 'input_length'\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(Embedding(5000, 128))  # Removed input_length\n",
        "lstm_model.add(LSTM(64))\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification\n",
        "\n",
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "lstm_model.fit(X_train_pad, y_train, epochs=5, batch_size=64)  # adjust epochs and batch_size\n",
        "\n",
        "# Predict using LSTM\n",
        "y_train_pred_lstm = (lstm_model.predict(X_train_pad) > 0.5).astype(int)\n",
        "y_test_pred_lstm = (lstm_model.predict(X_test_pad) > 0.5).astype(int)\n",
        "\n",
        "# Evaluate LSTM model\n",
        "print('LSTM')\n",
        "print('Training Set Performance')\n",
        "print('accuracy_score {:.4f}'.format(accuracy_score(y_train, y_train_pred_lstm)))\n",
        "print('f1_score {:.4f}'.format(f1_score(y_train, y_train_pred_lstm, average='weighted')))\n",
        "print('precision_score {:.4f}'.format(precision_score(y_train, y_train_pred_lstm, average='weighted')))\n",
        "print('recall_score {:.4f}'.format(recall_score(y_train, y_train_pred_lstm, average='weighted')))\n",
        "print('roc_auc_score {:.4f}'.format(roc_auc_score(y_train, y_train_pred_lstm, average='weighted')))\n",
        "print('--------------------------')\n",
        "print('Test Set Performance')\n",
        "print('accuracy_score {:.4f}'.format(accuracy_score(y_test, y_test_pred_lstm)))\n",
        "print('f1_score {:.4f}'.format(f1_score(y_test, y_test_pred_lstm, average='weighted')))\n",
        "print('precision_score {:.4f}'.format(precision_score(y_test, y_test_pred_lstm, average='weighted')))\n",
        "print('recall_score {:.4f}'.format(recall_score(y_test, y_test_pred_lstm, average='weighted')))\n",
        "print('roc_auc_score {:.4f}'.format(roc_auc_score(y_test, y_test_pred_lstm, average='weighted')))\n",
        "print('=' * 35)\n",
        "print('\\n')\n",
        "\n",
        "# Save the tokenizer and LSTM model\n",
        "with open('tokenizer.pkl', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "lstm_model.save('lstm_model.h5')\n",
        "\n",
        "# Update best model if LSTM has higher F1 score\n",
        "lstm_f1_score = f1_score(y_test, y_test_pred_lstm, average='weighted')\n",
        "if lstm_f1_score > best_f1_score:\n",
        "    best_f1_score = lstm_f1_score\n",
        "    best_model = lstm_model\n",
        "    best_model_name = 'LSTM'\n",
        "\n",
        "# Save the best model\n",
        "if best_model_name != 'LSTM':\n",
        "    with open(f'{best_model_name.lower().replace(\" \", \"_\")}_best_model.pkl', 'wb') as f:\n",
        "        pickle.dump(best_model, f)\n",
        "else:\n",
        "    best_model.save('best_lstm_model.h5')\n",
        "\n",
        "print(f\"Best model is {best_model_name} with F1 score: {best_f1_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_Rc8KkLBJDm",
        "outputId": "3bb7177d-c722-4b8a-b3ad-d547e7ad61e4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes\n",
            "Training Set Performance\n",
            "accuracy_score 0.9033\n",
            "f1_score 0.9033\n",
            "precision_score 0.9035\n",
            "recall_score 0.9033\n",
            "roc_auc_score 0.9033\n",
            "--------------------------\n",
            "Test Set Performance\n",
            "accuracy_score 0.8895\n",
            "f1_score 0.8895\n",
            "precision_score 0.8897\n",
            "recall_score 0.8895\n",
            "roc_auc_score 0.8896\n",
            "===================================\n",
            "\n",
            "\n",
            "Random Forest\n",
            "Training Set Performance\n",
            "accuracy_score 1.0000\n",
            "f1_score 1.0000\n",
            "precision_score 1.0000\n",
            "recall_score 1.0000\n",
            "roc_auc_score 1.0000\n",
            "--------------------------\n",
            "Test Set Performance\n",
            "accuracy_score 0.9219\n",
            "f1_score 0.9219\n",
            "precision_score 0.9219\n",
            "recall_score 0.9219\n",
            "roc_auc_score 0.9218\n",
            "===================================\n",
            "\n",
            "\n",
            "Epoch 1/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 143ms/step - accuracy: 0.6965 - loss: 0.5940\n",
            "Epoch 2/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 144ms/step - accuracy: 0.9087 - loss: 0.2416\n",
            "Epoch 3/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 144ms/step - accuracy: 0.9520 - loss: 0.1562\n",
            "Epoch 4/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 144ms/step - accuracy: 0.9759 - loss: 0.0849\n",
            "Epoch 5/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 142ms/step - accuracy: 0.9809 - loss: 0.0740\n",
            "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM\n",
            "Training Set Performance\n",
            "accuracy_score 0.9935\n",
            "f1_score 0.9935\n",
            "precision_score 0.9935\n",
            "recall_score 0.9935\n",
            "roc_auc_score 0.9935\n",
            "--------------------------\n",
            "Test Set Performance\n",
            "accuracy_score 0.8966\n",
            "f1_score 0.8965\n",
            "precision_score 0.8978\n",
            "recall_score 0.8966\n",
            "roc_auc_score 0.8964\n",
            "===================================\n",
            "\n",
            "\n",
            "Best model is Random Forest with F1 score: 0.9218587731034075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ydckYqolPmf1"
      },
      "outputs": [],
      "source": [
        "# import streamlit as st\n",
        "# import pickle\n",
        "# import re\n",
        "# from bs4 import BeautifulSoup\n",
        "# from nltk.corpus import stopwords\n",
        "# import nltk\n",
        "\n",
        "# # Download stopwords\n",
        "# nltk.download('stopwords')\n",
        "\n",
        "# # Load resources\n",
        "# with open(\"logistic_regression_model.pkl\", \"rb\") as model_file:\n",
        "#     model = pickle.load(model_file)\n",
        "\n",
        "# with open(\"tfidf_vectorizer.pkl\", \"rb\") as vec_file:\n",
        "#     vectorizer = pickle.load(vec_file)\n",
        "\n",
        "# with open(\"label_encoder.pkl\", \"rb\") as le_file:\n",
        "#     label_encoder = pickle.load(le_file)\n",
        "\n",
        "# # Preprocessing function\n",
        "# def preprocess(text):\n",
        "#     text = re.sub(r'[^a-zA-Z0-9]+', ' ', text)\n",
        "#     text = re.sub(r'(http|https|ftp)://[a-zA-Z0-9./]+', '', text)\n",
        "#     text = BeautifulSoup(text, 'lxml').get_text()\n",
        "#     text = \" \".join(text.split())\n",
        "#     text = \" \".join([word for word in text.lower().split() if word not in stopwords.words('english')])\n",
        "#     return text\n",
        "\n",
        "# # App UI config\n",
        "# st.set_page_config(page_title=\"🎬 Movie Sentiment Analyzer\", layout=\"centered\")\n",
        "\n",
        "# st.markdown(\n",
        "#     \"\"\"\n",
        "#     <style>\n",
        "#     .main {\n",
        "#         background-color: #f9f9f9;\n",
        "#         font-family: 'Segoe UI', sans-serif;\n",
        "#     }\n",
        "#     .title {\n",
        "#         color: #1f77b4;\n",
        "#         text-align: center;\n",
        "#     }\n",
        "#     .footer {\n",
        "#         text-align: center;\n",
        "#         font-size: 12px;\n",
        "#         color: #888;\n",
        "#         margin-top: 50px;\n",
        "#     }\n",
        "#     </style>\n",
        "#     \"\"\",\n",
        "#     unsafe_allow_html=True\n",
        "# )\n",
        "\n",
        "# # Title\n",
        "# st.markdown(\"<h1 class='title'>🎥 Movie Review Sentiment Analyzer</h1>\", unsafe_allow_html=True)\n",
        "# st.write(\"Write a review for your favorite movie and check if the sentiment is **Positive** or **Negative**!\")\n",
        "\n",
        "# # Movie selection\n",
        "# movies = [\n",
        "#     \"Inception\", \"Titanic\", \"Interstellar\", \"The Godfather\", \"The Dark Knight\",\n",
        "#     \"Forrest Gump\", \"The Shawshank Redemption\", \"Fight Club\", \"Avengers: Endgame\", \"Joker\"\n",
        "# ]\n",
        "# selected_movie = st.selectbox(\"🎬 Select a Movie\", movies)\n",
        "\n",
        "# # Review input\n",
        "# user_review = st.text_area(f\"📝 Write your review for *{selected_movie}*\", height=200)\n",
        "\n",
        "# # Predict button\n",
        "# if st.button(\"🔍 Analyze Sentiment\"):\n",
        "#     if user_review.strip() == \"\":\n",
        "#         st.warning(\"🚨 Please enter a review before analyzing.\")\n",
        "#     else:\n",
        "#         cleaned_review = preprocess(user_review)\n",
        "#         vectorized_review = vectorizer.transform([cleaned_review])\n",
        "#         prediction_encoded = model.predict(vectorized_review)[0]\n",
        "#         prediction_label = label_encoder.inverse_transform([prediction_encoded])[0] if hasattr(label_encoder, \"inverse_transform\") else prediction_encoded\n",
        "\n",
        "#         if prediction_label == 'pos':\n",
        "#             st.success(\"✅ Positive Sentiment! You seem to have liked the movie. 🎉\")\n",
        "#         else:\n",
        "#             st.error(\"❌ Negative Sentiment! You didn’t enjoy the movie much. 😢\")\n",
        "\n",
        "# # Footer\n",
        "# st.markdown(\"<div class='footer'>Made with ❤️ using Streamlit</div>\", unsafe_allow_html=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is a complete machine learning workflow that compares traditional ML models (`Naive Bayes`, `Random Forest`) with a deep learning model (`LSTM`) for **text classification** (probably sentiment analysis or similar task). Here's a **clear step-by-step explanation**:\n",
        "\n",
        "# ---\n",
        "\n",
        "# ## 🔶 1. **Importing Required Libraries**\n",
        "\n",
        "# ```python\n",
        "# from sklearn.naive_bayes import MultinomialNB\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# ```\n",
        "\n",
        "# * **scikit-learn**: For traditional ML models and evaluation metrics.\n",
        "# * **Keras**: For defining and training the LSTM deep learning model.\n",
        "# * **Tokenizer & Pad Sequences**: Converts raw text into numerical format for LSTM.\n",
        "\n",
        "# ---\n",
        "\n",
        "# ## 🔶 2. **Traditional Models: Naive Bayes & Random Forest**\n",
        "\n",
        "# ```python\n",
        "# models = {\n",
        "#     'Naive Bayes': MultinomialNB(),\n",
        "#     'Random Forest': RandomForestClassifier(),\n",
        "# }\n",
        "# ```\n",
        "\n",
        "# Defines two models to be trained on TF-IDF vectorized text data.\n",
        "\n",
        "# ---\n",
        "\n",
        "# ### 🔹 Loop Over Each Model\n",
        "\n",
        "# ```python\n",
        "# for model_name, model in models.items():\n",
        "#     model.fit(X_train_tfidf, y_train)\n",
        "# ```\n",
        "\n",
        "# * Fits each model on **TF-IDF transformed training data**.\n",
        "# * Predicts on both training and test sets.\n",
        "\n",
        "# ### 🔹 Evaluate Each Model\n",
        "\n",
        "# ```python\n",
        "#     print('accuracy_score', ...)\n",
        "#     print('f1_score', ...)\n",
        "# ```\n",
        "\n",
        "# * Evaluates using **accuracy, precision, recall, F1-score, ROC AUC** (weighted to handle class imbalance).\n",
        "# * Results are printed separately for **training** and **test** sets.\n",
        "\n",
        "# ### 🔹 Save Each Model\n",
        "\n",
        "# ```python\n",
        "#     filename = f'{model_name.lower().replace(\" \", \"_\")}_model.pkl'\n",
        "#     with open(filename, 'wb') as f:\n",
        "#         pickle.dump(model, f)\n",
        "# ```\n",
        "\n",
        "# * Saves each trained model as a `.pkl` file for later use or deployment.\n",
        "\n",
        "# ---\n",
        "\n",
        "# ## 🔶 3. **LSTM Deep Learning Model**\n",
        "\n",
        "# ### 🔹 Tokenize Text Data\n",
        "\n",
        "# ```python\n",
        "# tokenizer = Tokenizer(num_words=5000)\n",
        "# tokenizer.fit_on_texts(X_train['combined'])\n",
        "# ```\n",
        "\n",
        "# * Converts words into integers.\n",
        "# * `X_train['combined']` is a column where text is already preprocessed and combined (e.g., `title + review`).\n",
        "\n",
        "# ### 🔹 Convert Texts to Sequences and Pad\n",
        "\n",
        "# ```python\n",
        "# X_train_seq = tokenizer.texts_to_sequences(X_train['combined'])\n",
        "# X_train_pad = pad_sequences(X_train_seq, maxlen=max_length)\n",
        "# ```\n",
        "\n",
        "# * Converts tokenized texts to equal-length padded sequences for LSTM input.\n",
        "\n",
        "# ---\n",
        "\n",
        "# ### 🔹 Define & Train LSTM Model\n",
        "\n",
        "# ```python\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(5000, 128, input_length=max_length))\n",
        "# model.add(LSTM(64))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "# ```\n",
        "\n",
        "# * `Embedding`: Converts token IDs into dense vectors.\n",
        "# * `LSTM`: Learns sequential patterns.\n",
        "# * `Dense`: Final layer for **binary classification** using sigmoid.\n",
        "\n",
        "# ### 🔹 Compile and Fit\n",
        "\n",
        "# ```python\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# model.fit(X_train_pad, y_train, epochs=5, batch_size=64)\n",
        "# ```\n",
        "\n",
        "# * Trains the model for 5 epochs.\n",
        "\n",
        "# ---\n",
        "\n",
        "# ### 🔹 Predict and Evaluate\n",
        "\n",
        "# ```python\n",
        "# y_train_pred_lstm = (model.predict(X_train_pad) > 0.5).astype(int)\n",
        "# ```\n",
        "\n",
        "# * Predictions are probabilities → convert to class `0` or `1`.\n",
        "# * You can then evaluate using the same metrics (not shown here).\n",
        "\n",
        "# ---\n",
        "\n",
        "# ### 🔹 Save LSTM Artifacts\n",
        "\n",
        "# ```python\n",
        "# with open('tokenizer.pkl', 'wb') as handle:\n",
        "#     pickle.dump(tokenizer, handle)\n",
        "\n",
        "# model.save('lstm_model.h5')\n",
        "# ```\n",
        "\n",
        "# * Saves the tokenizer and the LSTM model (`.h5`) for deployment in Streamlit or Flask.\n",
        "\n",
        "# ---\n",
        "\n",
        "# ## ✅ Summary\n",
        "\n",
        "# | Component                      | Purpose                                    |\n",
        "# | ------------------------------ | ------------------------------------------ |\n",
        "# | `Naive Bayes`, `Random Forest` | Compare baseline ML classifiers            |\n",
        "# | `Tokenizer`, `LSTM`            | Build an advanced deep learning classifier |\n",
        "# | `TF-IDF` + `.pkl`              | Used with traditional models               |\n",
        "# | `Tokenizer` + `.h5`            | Used with LSTM                             |\n",
        "# | Evaluation Metrics             | To compare and track model performance     |\n",
        "# | Pickling                       | Makes models deployable                    |\n",
        "\n",
        "# ---\n",
        "\n",
        "# Would you like me to also add the missing **evaluation block for the LSTM part** or prepare this for **Streamlit deployment**?\n"
      ],
      "metadata": {
        "id": "AxaetfEU_PNK"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dnxw2S3m_PKJ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5tDkykQl_PIM"
      },
      "execution_count": 56,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}